{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from RNNHelper import (import_behaviors, dataframe_to_numpy, encode_articles,\n",
    "                       create_pos_neg, rnn_train_val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors = import_behaviors(\"../../data/mind_small_train/behaviors_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impression_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>history</th>\n",
       "      <th>impressions</th>\n",
       "      <th>length_history</th>\n",
       "      <th>history_split</th>\n",
       "      <th>impressions_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>U13740</td>\n",
       "      <td>11/11/2019 9:05:58 AM</td>\n",
       "      <td>N55189 N42782 N34694 N45794 N18445 N63302 N104...</td>\n",
       "      <td>N55689-1 N35729-0</td>\n",
       "      <td>9</td>\n",
       "      <td>[N55189, N42782, N34694, N45794, N18445, N6330...</td>\n",
       "      <td>[N55689-1, N35729-0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>U91836</td>\n",
       "      <td>11/12/2019 6:11:30 PM</td>\n",
       "      <td>N31739 N6072 N63045 N23979 N35656 N43353 N8129...</td>\n",
       "      <td>N20678-0 N39317-0 N58114-0 N20495-0 N42977-0 N...</td>\n",
       "      <td>82</td>\n",
       "      <td>[N31739, N6072, N63045, N23979, N35656, N43353...</td>\n",
       "      <td>[N20678-0, N39317-0, N58114-0, N20495-0, N4297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>U73700</td>\n",
       "      <td>11/14/2019 7:01:48 AM</td>\n",
       "      <td>N10732 N25792 N7563 N21087 N41087 N5445 N60384...</td>\n",
       "      <td>N50014-0 N23877-0 N35389-0 N49712-0 N16844-0 N...</td>\n",
       "      <td>16</td>\n",
       "      <td>[N10732, N25792, N7563, N21087, N41087, N5445,...</td>\n",
       "      <td>[N50014-0, N23877-0, N35389-0, N49712-0, N1684...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   impression_id user_id                   time  \\\n",
       "0              1  U13740  11/11/2019 9:05:58 AM   \n",
       "1              2  U91836  11/12/2019 6:11:30 PM   \n",
       "2              3  U73700  11/14/2019 7:01:48 AM   \n",
       "\n",
       "                                             history  \\\n",
       "0  N55189 N42782 N34694 N45794 N18445 N63302 N104...   \n",
       "1  N31739 N6072 N63045 N23979 N35656 N43353 N8129...   \n",
       "2  N10732 N25792 N7563 N21087 N41087 N5445 N60384...   \n",
       "\n",
       "                                         impressions  length_history  \\\n",
       "0                                  N55689-1 N35729-0               9   \n",
       "1  N20678-0 N39317-0 N58114-0 N20495-0 N42977-0 N...              82   \n",
       "2  N50014-0 N23877-0 N35389-0 N49712-0 N16844-0 N...              16   \n",
       "\n",
       "                                       history_split  \\\n",
       "0  [N55189, N42782, N34694, N45794, N18445, N6330...   \n",
       "1  [N31739, N6072, N63045, N23979, N35656, N43353...   \n",
       "2  [N10732, N25792, N7563, N21087, N41087, N5445,...   \n",
       "\n",
       "                                   impressions_split  \n",
       "0                               [N55689-1, N35729-0]  \n",
       "1  [N20678-0, N39317-0, N58114-0, N20495-0, N4297...  \n",
       "2  [N50014-0, N23877-0, N35389-0, N49712-0, N1684...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behaviors.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136047, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behaviors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating list of all articles in behaviors...\n",
      "Creating unique articles set\n",
      "Encoding articles in dataframe with integers...\n"
     ]
    }
   ],
   "source": [
    "behaviors, unique_articles, num_articles, article2idx = encode_articles(behaviors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create complete list of 'positive' articles...\n",
      "Create complete list of 'negative' articles...\n"
     ]
    }
   ],
   "source": [
    "n_hist = 5\n",
    "complete_list_1s, complete_list_0s = create_pos_neg(behaviors, n_hist_articles=n_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array, valid_array, train_targets_array, valid_targets_array, train_idx, test_idx = rnn_train_val_split(complete_list_1s, complete_list_0s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN with LSTM cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 8\n",
    "LR = 1e-4\n",
    "METRICS = ['AUC']\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build, Compiel and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 8)           398336    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               70144     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 469,781\n",
      "Trainable params: 469,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = keras.Sequential()\n",
    "lstm.add(layers.Embedding(input_dim=num_articles, output_dim=EMB_DIM))\n",
    "lstm.add(layers.LSTM(128))\n",
    "lstm.add(layers.Dense(10))\n",
    "lstm.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "lstm.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(LR),\n",
    "              metrics=METRICS)\n",
    "\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 217674 samples, validate on 54420 samples\n",
      "217674/217674 [==============================] - 68s 313us/sample - loss: 0.6964 - AUC: 0.4997 - val_loss: 0.6931 - val_AUC: 0.5067\n"
     ]
    }
   ],
   "source": [
    "lstm_hist = lstm.fit(train_array, train_targets_array, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                    validation_data=(valid_array, valid_targets_array), \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN with GRU cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, None, 8)           398336    \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 128)               52992     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 461,697\n",
      "Trainable params: 461,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gru = keras.Sequential()\n",
    "gru.add(layers.Embedding(input_dim=num_articles, output_dim=EMB_DIM))\n",
    "gru.add(layers.GRU(64))\n",
    "gru.add(layers.Dense(32))\n",
    "gru.add(layers.Dense(16))\n",
    "gru.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "gru.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(LR),\n",
    "              metrics=METRICS)\n",
    "\n",
    "gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 217674 samples, validate on 54420 samples\n",
      "217674/217674 [==============================] - 57s 263us/sample - loss: 0.6792 - AUC: 0.6267 - val_loss: 0.6707 - val_AUC: 0.6647\n"
     ]
    }
   ],
   "source": [
    "gru_hist = gru.fit(train_array, train_targets_array, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                    validation_data=(valid_array, valid_targets_array), \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav, columndict = dataframe_to_numpy(behaviors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'impression_id': 0,\n",
       " 'user_id': 1,\n",
       " 'time': 2,\n",
       " 'history': 3,\n",
       " 'impressions': 4,\n",
       " 'length_history': 5,\n",
       " 'history_split': 6,\n",
       " 'impressions_split': 7,\n",
       " 'history_int': 8,\n",
       " 'impressions_int_1': 9,\n",
       " 'impressions_int_0': 10}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columndict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(420)\n",
    "test_indexes = random.sample(test_idx, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_test = behav[test_indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_articles_int = [article2idx[art] for art in unique_articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 %\r"
     ]
    }
   ],
   "source": [
    "num_test_negs = 99\n",
    "test_trajectories = []\n",
    "test_targets = []\n",
    "number_iters = len(behav_test)\n",
    "iteration = 0\n",
    "\n",
    "for session in behav_test:\n",
    "    iteration += 1\n",
    "    progress = round(iteration/number_iters*100, 1)\n",
    "    print(f\"{progress} %\", end=\"\\r\")\n",
    "    history_int = session[columndict[\"history_int\"]]\n",
    "    short_hist = history_int[-n_hist:]\n",
    "    impression_int_1 = session[columndict[\"impressions_int_1\"]]\n",
    "    test_trajectories += short_hist\n",
    "    test_trajectories += [impression_int_1[0]]\n",
    "    test_targets.append(1)\n",
    "    \n",
    "    negative_articles = list(set(unique_articles_int) - set(history_int))\n",
    "    len_negative_articles = len(negative_articles)\n",
    "    for t in range(num_test_negs):\n",
    "        j = np.random.randint(len_negative_articles)\n",
    "        neg = short_hist + [negative_articles[j]]\n",
    "        test_trajectories += neg\n",
    "        test_targets.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = np.array(test_trajectories)\n",
    "n_test = len(test_trajectories)//6\n",
    "test_input = test_input.reshape(n_test, 6,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_rating(test_test, model):\n",
    "    predictions = model.predict(test_test)\n",
    "    sorted_pred = sorted(predictions, reverse=True)\n",
    "    get_item = predictions[0]\n",
    "    rank = sorted_pred.index(get_item)\n",
    "\n",
    "    if rank < K:\n",
    "        hr = 1\n",
    "        ndcg = math.log(2) / math.log(rank+2)\n",
    "        rr = 1/(rank+1)\n",
    "    else:\n",
    "        hr = 0\n",
    "        ndcg = 0\n",
    "        rr = 0\n",
    "    \n",
    "    return (hr, ndcg, rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.98 %\r"
     ]
    }
   ],
   "source": [
    "hits, ndcgs, rrs = [], [], []\n",
    "number_iters = len(test_input)\n",
    "\n",
    "for i in range(0, len(test_input), 100):\n",
    "    progress = round(i/number_iters*100, 1)\n",
    "    print(f\"{progress} %\", end=\"\\r\")\n",
    "    test_test = test_input[i:i+100]\n",
    "    hr, ndcg, rr = eval_one_rating(test_test, lstm)\n",
    "    hits.append(hr)\n",
    "    ndcgs.append(ndcg)\n",
    "    rrs.append(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit ratio:             0.2096\n",
      "Mean reciprocal rank:  0.10394746031746031\n",
      "NDCG@10:          0.1286773984962387\n"
     ]
    }
   ],
   "source": [
    "hr = np.array(hits).mean()\n",
    "mrr = np.array(rrs).mean()\n",
    "ndcg = np.array(ndcgs).mean()\n",
    "\n",
    "print(\"Hit ratio:            \", hr)\n",
    "print(\"Mean reciprocal rank: \", mrr)\n",
    "print(f\"NDCG@{K}:         \", ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with title embedding (word vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"../../data/mind_small_train/news_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>title_entities</th>\n",
       "      <th>abstract_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N55528</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAGH0ET.html</td>\n",
       "      <td>[{\"Label\": \"Prince Philip, Duke of Edinburgh\",...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N19639</td>\n",
       "      <td>health</td>\n",
       "      <td>weightloss</td>\n",
       "      <td>50 Worst Habits For Belly Fat</td>\n",
       "      <td>These seemingly harmless habits are holding yo...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAB19MK.html</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N61837</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJgNsz.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id   category      subcategory  \\\n",
       "0     N55528  lifestyle  lifestyleroyals   \n",
       "1     N19639     health       weightloss   \n",
       "2     N61837       news        newsworld   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
       "1                      50 Worst Habits For Belly Fat   \n",
       "2  The Cost of Trump's Aid Freeze in the Trenches...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Shop the notebooks, jackets, and more that the...   \n",
       "1  These seemingly harmless habits are holding yo...   \n",
       "2  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
       "\n",
       "                                             url  \\\n",
       "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
       "1  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
       "2  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
       "\n",
       "                                      title_entities  \\\n",
       "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
       "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
       "2                                                 []   \n",
       "\n",
       "                                   abstract_entities  \n",
       "0                                                 []  \n",
       "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
       "2  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49792"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_news = news[news.article_id.isin(unique_articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49792, 8), (50434, 8))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_news.shape, news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_article_ids = unique_news.iloc[:, 0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N55528', 'N19639', 'N61837']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_article_ids[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_article_titles = unique_news.iloc[:, 3].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Brands Queen Elizabeth, Prince Charles, and Prince Philip Swear By',\n",
       " '50 Worst Habits For Belly Fat',\n",
       " \"The Cost of Trump's Aid Freeze in the Trenches of Ukraine's War\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_article_titles[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 60000\n",
    "title_length = 20\n",
    "vectorize_layer = TextVectorization(\n",
    "   # standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=title_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(unique_article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = vectorize_layer(unique_article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_array = K.eval(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"\"\n",
    "for int_word in K.eval(vectorize_layer(unique_article_titles)[1]):\n",
    "    example += vectorize_layer.get_vocabulary()[int_word] + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 worst habits for belly fat\n"
     ]
    }
   ],
   "source": [
    "print(example.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N19639'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_article_ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N19639</td>\n",
       "      <td>50 Worst Habits For Belly Fat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id                          title\n",
       "1     N19639  50 Worst Habits For Belly Fat"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news[news.article_id==\"N19639\"][[\"article_id\", \"title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "articleid2title = {art_id: title for art_id, title in zip(unique_article_ids,\n",
    "                                                          unique_article_titles\n",
    "                                                         )\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50 Worst Habits For Belly Fat'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articleid2title[\"N19639\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217674"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2564, 32867, 40363, 32732, 29054, 14681],\n",
       "       [ 2564, 32867, 40363, 32732, 29054, 45556]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2article = {i: a for a, i in article2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsarticle2idx = {art: i for i, art in enumerate(unique_article_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%\r"
     ]
    }
   ],
   "source": [
    "train_vec_idx = []\n",
    "total_iters = len(train_array)\n",
    "for i, traj in enumerate(train_array):\n",
    "    progress = round(i/total_iters*100, 1)\n",
    "    print(f'{progress}%', end='\\r')\n",
    "    for j, int_id in enumerate(traj):\n",
    "        #print(j, int_id)\n",
    "        article_id = idx2article[int_id]\n",
    "        #print(article_id)\n",
    "        text = articleid2title[article_id]\n",
    "        #print(text)\n",
    "        vec_idx = newsarticle2idx[article_id]\n",
    "        train_vec_idx.append(vec_idx)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec_array = vectorizer_array[train_vec_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5752,     2,    96,     9,  3121,   150,  1300,    34,    50,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [ 7588,  3692,  3327,   923,    32,  1504,   824,  6301,   134,\n",
       "           70,  2991,  5392,   436,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [   32,  1716,    49,     4,   857,   184,     4,  8135,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [  981,  1795,    70,  3178,  2012,   695,     3,     7,  4271,\n",
       "           82,    70,    53,  5214,   673,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [  214,  3616,     2,   974,    22,  1197,     7,  5261, 22887,\n",
       "            2,  2472,   531,     3, 10343, 34621,     0,     0,     0,\n",
       "            0,     0]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vec_array[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"\"\n",
    "for int_word in train_vec_array[0]:\n",
    "    example += vectorize_layer.get_vocabulary()[int_word] + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'renovations to make and skip before selling your home            '"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_emb_dim = 32\n",
    "max_len = 20\n",
    "len_trajectory = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "title_input (InputLayer)     [(None, 6, 20)]           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_32 (TimeDis (None, 6, 20, 32)         1920032   \n",
      "_________________________________________________________________\n",
      "time_distributed_33 (TimeDis (None, 6, 64)             16640     \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,949,121\n",
      "Trainable params: 1,949,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "title_seq = Input(shape=(len_trajectory, max_len,), name='title_input')\n",
    "\n",
    "word_emb = tf.keras.layers.TimeDistributed(Embedding(input_dim=max_features+1, \n",
    "                                                output_dim=title_emb_dim,\n",
    "                                                input_length=max_len, mask_zero=True,\n",
    "                                                input_shape=(max_len, )))(title_seq)\n",
    "# maybe bidirectional?Bidirectional(LSTM(32))\n",
    "title_embedded = tf.keras.layers.TimeDistributed(layers.Bidirectional(layers.LSTM(32)))(word_emb)      \n",
    "x = layers.LSTM(32)(title_embedded)\n",
    "prediction = layers.Dense(1, activation='sigmoid')(x)\n",
    "lstm_titlevec = tf.keras.Model(inputs=title_seq , outputs=prediction)\n",
    "\n",
    "lstm_titlevec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec_array = train_vec_array.reshape(len(train_targets_array), 6, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_titlevec.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                      optimizer=tf.keras.optimizers.Adam(1e-4), metrics=['AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 114s 267ms/step - loss: 0.7009 - auc: 0.5079\n"
     ]
    }
   ],
   "source": [
    "titlevec_hist = lstm_titlevec.fit(train_vec_array, train_targets_array, \n",
    "                                  epochs=1, \n",
    "                                  batch_size=512,\n",
    "                    #validation_data=(valid_array, valid_targets_array), \n",
    "                                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.98 %\r"
     ]
    }
   ],
   "source": [
    "hits, ndcgs, rrs = [], [], []\n",
    "number_iters = len(test_input)\n",
    "\n",
    "for i in range(0, len(test_input), 100):\n",
    "    progress = round(i/number_iters*100, 1)\n",
    "    print(f\"{progress} %\", end=\"\\r\")\n",
    "    test_test = test_input[i:i+100]\n",
    "    hr, ndcg, rr = eval_one_rating(test_test, lstm)\n",
    "    hits.append(hr)\n",
    "    ndcgs.append(ndcg)\n",
    "    rrs.append(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit ratio:             0.2096\n",
      "Mean reciprocal rank:  0.10394746031746031\n",
      "NDCG@10:          0.1286773984962387\n"
     ]
    }
   ],
   "source": [
    "hr = np.array(hits).mean()\n",
    "mrr = np.array(rrs).mean()\n",
    "ndcg = np.array(ndcgs).mean()\n",
    "\n",
    "print(\"Hit ratio:            \", hr)\n",
    "print(\"Mean reciprocal rank: \", mrr)\n",
    "print(f\"NDCG@{K}:         \", ndcg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
