{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Collaborative Filtering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 15:46:47\n"
     ]
    }
   ],
   "source": [
    "layers = \"[64,32,16,8]\"\n",
    "\n",
    "now = datetime.now()\n",
    "today=datetime.today()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out_file = f\"pretrain/small_MLP_{layers}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = \"small_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users, num_articles = 0, 0\n",
    "with open(train_filename, \"r\") as f:\n",
    "    header = f.readline()\n",
    "    line = f.readline()\n",
    "    while line != None and line != \"\":\n",
    "        line_list = line.split(\",\")\n",
    "        u, i = int(line_list[2]), int(line_list[3])\n",
    "        num_users = max(num_users, u)\n",
    "        num_articles = max(num_articles, i)\n",
    "        line = f.readline()\n",
    "\n",
    "num_users += 1\n",
    "num_articles += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40331, 31415)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users, num_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id,article,user_id_code,article_id_code\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = sp.dok_matrix((num_users, num_articles), dtype=np.float32)\n",
    "\n",
    "with open(train_filename, \"r\") as f:\n",
    "    header = f.readline()\n",
    "    print(header)\n",
    "    line = f.readline()\n",
    "    while line != None and line != \"\":\n",
    "        line_list = line.split(\",\")\n",
    "        user, article = int(line_list[2]), int(line_list[3])\n",
    "        train[user, article] = 1.0\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filename = \"small_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id,article,user_id_code,article_id_code\n",
      "\n",
      "U13740,N31801,1810,11677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_positives = []\n",
    "with open(test_filename, \"r\") as f:\n",
    "    header = f.readline()\n",
    "    print(header)\n",
    "    line = f.readline()\n",
    "    print(line)\n",
    "    while line != None and line != \"\":\n",
    "        line_list = line.split(\",\")\n",
    "        #print(line_list)\n",
    "        user, article = int(line_list[2]), int(line_list[3])\n",
    "        #print(user, article)                                            \n",
    "        test_positives.append([user, article])\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39846"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neg_filename = \"small_test_negatives.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_negatives = []\n",
    "with open(test_neg_filename, \"r\") as f:\n",
    "    line = f.readline()\n",
    "    while line != None and line != \"\":\n",
    "        line_list = line.split(\"\\t\")\n",
    "        #print(line_list)\n",
    "        negatives = []\n",
    "        for neg in line_list[1: ]:\n",
    "            negatives.append(int(neg))\n",
    "        test_negatives.append(negatives)\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39846"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [16, 8]\n",
    "reg_layers = [0, 0]\n",
    "num_layer = len(layers)\n",
    "learning_rate = 0.001\n",
    "batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "article_input = Input(shape=(1,), dtype='int32', name='article_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/nf/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "MLP_Embedding_User = Embedding(input_dim=num_users, output_dim=layers[0]//2, \n",
    "                               name='user_embedding', input_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_Embedding_Article = Embedding(input_dim=num_articles, output_dim=layers[0]//2, \n",
    "                               name='article_embedding', input_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_latent = Flatten()(MLP_Embedding_User(user_input))\n",
    "article_latent = Flatten()(MLP_Embedding_Article(article_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = Concatenate(axis=-1)([user_latent, article_latent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/nf/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "for idx in range(1, num_layer):\n",
    "    layer = Dense(layers[idx], activation='relu', name='layer%d' %idx)\n",
    "    vector = layer(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name = 'prediction')(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[user_input, article_input], outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/nf/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_negatives = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input, article_input, labels = [],[],[]\n",
    "for (u, i) in train.keys():\n",
    "    # positive instance\n",
    "    user_input.append(u)\n",
    "    article_input.append(i)\n",
    "    labels.append(1)\n",
    "    # negative instances\n",
    "    for t in range(num_negatives):\n",
    "        j = np.random.randint(num_articles)\n",
    "        while (u, j) in train.keys():\n",
    "            j = np.random.randint(num_articles)\n",
    "        user_input.append(u)\n",
    "        article_input.append(j)\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4042170/4042170 [==============================] - 82s 20us/sample - loss: 0.2930\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "hist = model.fit([np.array(user_input), np.array(article_input)], #input\n",
    "                         np.array(labels), # labels \n",
    "                         batch_size=batch_size, epochs=1, verbose=1, shuffle=True)\n",
    "t2 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "article_input (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 8)         322648      user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "article_embedding (Embedding)   (None, 1, 8)         251320      article_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 8)            0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 8)            0           article_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16)           0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 8)            136         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            9           layer1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 574,113\n",
      "Trainable params: 574,113\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1810, 11677]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_positives[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_rating(idx):\n",
    "    rating = test_positives[idx]\n",
    "    items = test_negatives[idx]\n",
    "    u = rating[0]\n",
    "    get_item = rating[1]\n",
    "    items.append(get_item)\n",
    "    # Get prediction scores\n",
    "    map_item_score = {}\n",
    "    users = np.full(len(items), u, dtype = 'int32')\n",
    "    predictions = model.predict([users, np.array(items)], \n",
    "                                batch_size=100, verbose=0)\n",
    "    for i in range(len(items)):\n",
    "        item = items[i]\n",
    "        map_item_score[item] = predictions[i]\n",
    "    items.pop()\n",
    "    \n",
    "    # Evaluate top rank list\n",
    "    ranklist = heapq.nlargest(K, map_item_score, key=map_item_score.get)\n",
    "    \n",
    "    if get_item in ranklist:\n",
    "        hr = 1\n",
    "        i = ranklist.index(get_item)\n",
    "        ndcg = math.log(2) / math.log(i+2)\n",
    "    else:\n",
    "        hr = 0\n",
    "        ndcg = 0\n",
    "   \n",
    "    return (hr, ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits, ndcgs = [], []\n",
    "for idx in range(len(test_positives)):\n",
    "    hr, ndcg = eval_one_rating(idx)\n",
    "    hits.append(hr)\n",
    "    ndcgs.append(ndcgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = np.array(hits).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7562114139436832"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
