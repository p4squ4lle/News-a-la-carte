{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis for news consumption (Part 2)\n",
    "In this second part of our exploratory data analysis, we want to find out more about the articles, so let's start with loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from progressbar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"../data/MINDlarge_train/news_processed.csv\")\n",
    "behaviors_by_date = pd.read_csv(\"../data/MINDlarge_train/behaviors_by_date_large.csv\")\n",
    "category_weekday_df = pd.read_csv(\"../data/MINDlarge_train/category_weekday_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_by_date.history = behaviors_by_date.history.str.split(' ')\n",
    "behaviors_by_date.impressions = behaviors_by_date.impressions.str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_by_date_np = behaviors_by_date.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have information as to what was being recommended at a certain session and what was being clicked at that session, (although we don't know on what ground these recommendations were carried out). So first of all, we can **identify the most clicked articles**. To do that, we count the clicked article IDs, sort them from highest to lowest click numbers, and map the IDs to the titles and their categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked=[]\n",
    "for row in behaviors_by_date_np:\n",
    "    for impression in row[4]:\n",
    "        if impression[-1] == '1':\n",
    "            clicked.append(impression[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_df = pd.DataFrame(clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_clicked = clicked_df.iloc[:, 0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_clicked_df = pd.DataFrame(most_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_clicked_df.reset_index(inplace=True)\n",
    "most_clicked_df.columns = ['article_id', 'clicks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_clicked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_clicked_df.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_np = news.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_ids = []\n",
    "titles = []\n",
    "for row in news_np:\n",
    "    article_ids.append(row[0])\n",
    "    titles.append(row[3])\n",
    "    \n",
    "title_dict = dict(zip(article_ids, titles))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "values = []\n",
    "for row in news_np:\n",
    "    keys.append(row[0]) \n",
    "    values.append(row[1])\n",
    "\n",
    "category_dict = dict(zip(keys, values))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, article_id in enumerate(most_clicked_df.article_id[:5]):\n",
    "    print(title_dict[article_id])\n",
    "    print(most_clicked_df.iloc[i, 1])\n",
    "    print(category_dict[article_id]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so these are obviously not earth-shattering news, but that's what people seem to be interested in.\n",
    "With the **article on 5th place having only 60% of clicks of the top position**, let's look **how clicks are distributed** in general:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_clicks = px.histogram(most_clicked_df, x= 'clicks', nbins=250,\n",
    "                                color_discrete_sequence=['lime'],\n",
    "                              marginal='rug',\n",
    "                                labels={'category': 'Categories', 'weekday': 'Weekdays', 'clicks': 'Number of Clicks'})\n",
    "article_clicks.update_layout({\n",
    "'plot_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "'paper_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "'font_color' : 'white'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh wow! We can clealry see that there is so **many articles having relatively few clicks vs. a few articles having a lot of clicks**. Let's now check what were the **most read articles in the user histories**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_in_history = []\n",
    "for row in behaviors_by_date_np:\n",
    "    for article_id in row[3]:\n",
    "        articles_in_history.append(article_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(articles_in_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_in_history[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_in_history_count = Counter(articles_in_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_in_history_count['N59850']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_in_history_count = sorted(articles_in_history_count.items(),key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in articles_in_history_count[:5]:\n",
    "    print(title_dict[pair[0]])\n",
    "    print(pair[1])\n",
    "    print(category_dict[pair[0]])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, we now also find an article that can be considered of political content. Unfortunately, we also find a **cleansing artifact**: when remapping the redundant article IDs, we also homogenized a daily cartoon due to it's having the same title every day! This won't be too much of a problem for our models, but we clearly **need to dethrone this impostor**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in articles_in_history_count[1:6]:\n",
    "    print(title_dict[pair[0]])\n",
    "    print(pair[1])\n",
    "    print(category_dict[pair[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like we did for clicked articles, let's check the **distribution of read articles in histories**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_read = []\n",
    "count=[]\n",
    "for pair in articles_in_history_count:\n",
    "    articles_read.append(pair[0])\n",
    "    count.append(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_read_df = pd.DataFrame(list(zip(articles_read, count)), columns = ['article_id', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_read_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_read = px.histogram(articles_read_df, x= 'count', nbins=100,\n",
    "                                color_discrete_sequence=['deeppink'],\n",
    "                              marginal='rug',\n",
    "                                labels={'category': 'Categories', 'weekday': 'Weekdays', 'count': 'Number of Clicks'})\n",
    "articles_read.update_layout({\n",
    "'plot_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "'paper_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "'font_color' : 'white'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so here we have pretty much the **same situation like in clicked articles**: very few very often read articles vs a whole lot of less frequently read ones. \n",
    "\n",
    "Let's now check the **ratio of clicked vs. the total of suggested articles at specific sessions**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_by_date['impression_count'] = behaviors_by_date.impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_by_date['impression_count'] = behaviors_by_date.impression_count.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_by_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked, non_clicked = [], []\n",
    "\n",
    "for row in behaviors_by_date_np:\n",
    "    clicked_per_session = []\n",
    "    non_clicked_per_session = []\n",
    "    for article_id in row[4]:\n",
    "        if article_id[-1] == '1':\n",
    "            clicked_per_session.append(article_id[:-2])\n",
    "        if article_id[-1] == '0':\n",
    "            non_clicked_per_session.append(article_id[:-2])\n",
    "    clicked.append(clicked_per_session)\n",
    "    non_clicked.append(non_clicked_per_session)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_by_date['clicked'] = pd.Series(clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_by_date['non_clicked'] = pd.Series(non_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_by_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_by_date['click_length'] =   behaviors_by_date.clicked.map(len)\n",
    "behaviors_by_date['non_click_length'] = behaviors_by_date.non_clicked.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_by_date_np_2 = behaviors_by_date.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = []\n",
    "for row in behaviors_by_date_np_2:\n",
    "    ratio = row[12] / row[8]\n",
    "    ratios.append(round(ratio,2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_by_date['click_ratio'] = pd.Series(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_by_date.click_ratio.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_by_date.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_by_date.to_csv(\"../data/MINDlarge_train/beahviors_by_date_clicks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_by_date = pd.read_csv('../data/MINDlarge_train/beahviors_by_date_clicks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_ratios = px.histogram(behaviors_by_date, x='click_ratio', \n",
    "                            labels={'click_ratio': 'Proportion of Clicked Suggestions'}, color_discrete_sequence=['aqua']\n",
    "                            )\n",
    "\n",
    "\n",
    "click_ratios.update_layout({\n",
    "'plot_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "'paper_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "'font_color' : 'white'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, **at most of the sessions less than one of ten suggested articles has been clicked**. There also seem to be some special circumstances under which every second article has been clicked, although we cannot (and fortunately don't need to) reconstruct these today. **This concludes our exploratory data analysis**. See you in the next notebook, where we will be building our first, more conventional recommender systems!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
